{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a31c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARY\n",
    "!uv pip install -q --system numba-cuda==0.4.0\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Enable the CUDA simulator. This MUST be set BEFORE numba imports or kernel definitions.\n",
    "os.environ[\"NUMBA_ENABLE_CUDASIM\"] = \"1\"\n",
    "from numba import cuda\n",
    "from numba import config\n",
    "\n",
    "# --- Configuration & Data Preparation ---\n",
    "\n",
    "config.CUDA_ENABLE_PYNVJITLINK = 1\n",
    "\n",
    "# Prepare character data (ASCII values for A-H, 8 characters total)\n",
    "characters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "data = np.array([ord(c) for c in characters], dtype=np.uint8)\n",
    "data_size = len(data) # 8 elements\n",
    "\n",
    "# --- 1D Kernel Definition (using gidx, bidx, tidx) ---\n",
    "\n",
    "@cuda.jit\n",
    "def kernel_1d_dims(arr):\n",
    "    # gidx: Global ID index (Thread ID in the entire grid)\n",
    "    gidx = cuda.grid(1)\n",
    "\n",
    "    # bidx: Block ID (Block index in the grid)\n",
    "    bidx = cuda.blockIdx.x\n",
    "    # tidx: Thread ID (Thread index within the block)\n",
    "    tidx = cuda.threadIdx.x\n",
    "\n",
    "    if gidx < arr.size:\n",
    "        # Standard Python print works via the simulator\n",
    "        print(f\"BID: {bidx}, TID: {tidx}, GID: {gidx}, Char: {chr(arr[gidx])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb7a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 1: OPERATIONS WITH THREADS AND BLOCKS\n",
    "\n",
    "blocks_per_grid_ex1 = 2\n",
    "threads_per_block_ex1 = 2\n",
    "# Total threads = 2 x 2 = 4\n",
    "\n",
    "kernel_1d_dims[blocks_per_grid_ex1, threads_per_block_ex1](data)\n",
    "cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 2: OPERATIONS WITH THREADS AND BLOCKS\n",
    "\n",
    "blocks_per_grid_ex1 = 2\n",
    "threads_per_block_ex1 = 8\n",
    "# Total threads = 2 x 8 = 16\n",
    "\n",
    "kernel_1d_dims[blocks_per_grid_ex1, threads_per_block_ex1](data)\n",
    "cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05650d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 3: OPERATIONS WITH THREADS AND BLOCKS\n",
    "\n",
    "@cuda.jit\n",
    "def whoami():\n",
    "    # Compute block id in a 3D grid\n",
    "    block_id = (\n",
    "        cuda.blockIdx.x +\n",
    "        cuda.blockIdx.y * cuda.gridDim.x +\n",
    "        cuda.gridDim.x * cuda.gridDim.y\n",
    "    )\n",
    "\n",
    "    # Threads per block\n",
    "    threads_per_block = (\n",
    "        cuda.blockDim.x * cuda.blockDim.y\n",
    "    )\n",
    "\n",
    "    # Offset of this block\n",
    "    block_offset = block_id * threads_per_block\n",
    "\n",
    "    # Compute thread id inside block\n",
    "    thread_offset = (\n",
    "        cuda.threadIdx.x +\n",
    "        cuda.threadIdx.y * cuda.blockDim.x +\n",
    "        cuda.blockDim.x * cuda.blockDim.y\n",
    "    )\n",
    "\n",
    "    # Global thread id across all blocks\n",
    "    global_id = block_offset + thread_offset\n",
    "\n",
    "\n",
    "    print(f\"{global_id:03d} | Block[x, y]({cuda.blockIdx.x} {cuda.blockIdx.y}) = {block_id:3d} | \"\n",
    "          f\"Thread[x, y] ({cuda.threadIdx.x} {cuda.threadIdx.y} ) = {thread_offset:3d} BlockDim.x {cuda.blockDim.x} BlockDim.y {cuda.blockDim.y} GridDim.x {cuda.gridDim.x} GridDim.y {cuda.gridDim.y}\")\n",
    "\n",
    "\n",
    "b_x, b_y = 2, 2\n",
    "t_x, t_y = 4, 1\n",
    "\n",
    "blocks_per_grid = (b_x, b_y)\n",
    "threads_per_block = (t_x, t_y)\n",
    "\n",
    "total_blocks = b_x * b_y\n",
    "total_threads = t_x * t_y\n",
    "print(f\"{total_blocks} blocks/grid\")\n",
    "print(f\"{total_threads} threads/block\")\n",
    "print(f\"{total_blocks * total_threads} total threads\\n\")\n",
    "\n",
    "# Launch kernel\n",
    "whoami[blocks_per_grid, threads_per_block]()\n",
    "\n",
    "# Wait for GPU to finish (like cudaDeviceSynchronize)\n",
    "cuda.synchronize()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
