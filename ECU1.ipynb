{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d8bc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola mundo\n"
     ]
    }
   ],
   "source": [
    "# LIBRARY\n",
    "\n",
    "!uv pip install -q --system numba-cuda==0.4.0\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import time\n",
    "import os\n",
    "from numba import config\n",
    "config.CUDA_ENABLE_PYNVJITLINK = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b447b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMLE 1: INITIALIZE THE GPU AND CPU\n",
    "\n",
    "# Libraryes\n",
    "!uv pip install -q --system numba-cuda==0.4.0\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from numba import cuda\n",
    "from numba import config\n",
    "\n",
    "# --- Configuration & Data Preparation ---\n",
    "\n",
    "config.CUDA_ENABLE_PYNVJITLINK = 1\n",
    "\n",
    "@cuda.jit\n",
    "def first_kernel(a, result):\n",
    "  idx = cuda.grid(1)\n",
    "  if idx < a.size:\n",
    "    result[idx] = a[idx]\n",
    "\n",
    "# HOST CPU\n",
    "def main():\n",
    "  #2. Initialize data on CPU\n",
    "  N = 10_000_000\n",
    "  a_cpu = np.arange(N, dtype = np.float32)\n",
    "\n",
    "  #-----------------------------------------\n",
    "  #CPU computation\n",
    "  #-----------------------------------------\n",
    "  start = time.time()\n",
    "  result_cpu = a_cpu\n",
    "  cpu_time = time.time() - start\n",
    "  print(f\"CPU Time: {cpu_time * 1e3:.2f}\")\n",
    "\n",
    "  #-----------------------------------------\n",
    "  #GPU computation\n",
    "  #-----------------------------------------\n",
    "  #2.- Transfer from CPU to GPU\n",
    "  start = time.time()\n",
    "  a_gpu = cuda.to_device(a_cpu)\n",
    "  result_gpu = cuda.device_array_like(a_cpu) # reserve memory\n",
    "  transfer_in_time = time.time() - start\n",
    "\n",
    "  # Kernel launch\n",
    "  \"\"\"\n",
    "  Cada bloque contiene 128 hilos\n",
    "  \"\"\"\n",
    "  threads_per_block = 128\n",
    "  blocks_per_grid = (N + threads_per_block -1) //threads_per_block # (10_000_000 + 127) / 128 = 78,125 blocks\n",
    "  start = time.time()\n",
    "  first_kernel[blocks_per_grid, threads_per_block](a_cpu, result_gpu) # lunch kernel\n",
    "  cuda.synchronize()\n",
    "  kernel_time = time.time() - start\n",
    "\n",
    "  #Copy back\n",
    "  start = time.time()\n",
    "  result_from_gpu = result_gpu.copy_to_host()\n",
    "  cuda.synchronize()\n",
    "  transfer_out_time = time.time() - start\n",
    "\n",
    "  #Report\n",
    "  print(f\"GPU transfer to device: {transfer_in_time * 1e3:.2f} ms\")\n",
    "  print(f\"GPU kernel execution: {kernel_time * 1e3:.2f} ms\")\n",
    "  print(f\"GPU transfer to host: {transfer_out_time * 1e3:.2f} ms\")\n",
    "  print(f\"Total GPU time: {transfer_in_time + kernel_time + transfer_out_time * 1e3:.2f} ms\")\n",
    "\n",
    "  #cleanup\n",
    "  del a_gpu, result_gpu\n",
    "  cuda.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
