{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada3dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARY\n",
    "!uv pip install -q --system numba-cuda==0.4.0\n",
    "# !pip install pynvjitlink-cu12 \n",
    "%pip install pynvjitlink-cu12\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import time\n",
    "import os\n",
    "from numba import config\n",
    "import numba\n",
    "config.CUDA_ENABLE_PYNVJITLINK=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e77d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 1: VECTOR ADDITION\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "@numba.cuda.jit\n",
    "def vector_add_kernel(a, b, c):\n",
    "  \"\"\"\n",
    "  Cada hilo calcula un elemento: c[i] = a[i] + b[i]\n",
    "  \"\"\"\n",
    "\n",
    "  #Calcula el índice del subproceso global\n",
    "  idx = cuda.grid(1)\n",
    "\n",
    "  # Comprobación de límites\n",
    "  # Operacion Lineal\n",
    "  if idx < c.size:\n",
    "    c[idx] = a[idx] + b[idx]\n",
    "\n",
    "def main():\n",
    "  N_large = 10_000_000\n",
    "  a = np.random.randn(N_large).astype(np.float32)\n",
    "  b = np.random.randn(N_large).astype(np.float32)\n",
    "  c = np.zeros(N_large, dtype=np.float32)\n",
    "\n",
    "  d_a = cuda.to_device(a)\n",
    "  d_b = cuda.to_device(b)\n",
    "  d_c = cuda.to_device(c)\n",
    "\n",
    "  treads_per_block = 256\n",
    "  blocks_per_grid = math.ceil(N_large / treads_per_block)\n",
    "\n",
    "  # Warrup \"Significa calentar el Chip de la GPU\"\n",
    "  vector_add_kernel[blocks_per_grid, treads_per_block](d_a, d_b, d_c)\n",
    "  cuda.synchronize()\n",
    "\n",
    "  # GPU timing\n",
    "  start = time.time()\n",
    "  vector_add_kernel[blocks_per_grid, treads_per_block](d_a, d_b, d_c)\n",
    "  cuda.synchronize()\n",
    "  gpu_time = (time.time() - start) * 1000\n",
    "\n",
    "  result = d_c.copy_to_host()\n",
    "\n",
    "  #GPU timing\n",
    "  cpu_start = time.time()\n",
    "  expected = a + b\n",
    "  cpu_time = (time.time() - cpu_start) * 1000\n",
    "\n",
    "  #Warrup\n",
    "  vector_add_kernel[blocks_per_grid, treads_per_block](d_a, d_b, d_c)\n",
    "  cuda.synchronize()\n",
    "\n",
    "  #GPU timing\n",
    "  start = time.time()\n",
    "  vector_add_kernel[blocks_per_grid, treads_per_block](d_a, d_b, d_c)\n",
    "  cuda.synchronize()\n",
    "  gpu_time = (time.time() - start) * 1000\n",
    "\n",
    "  result = d_c.copy_to_host()\n",
    "\n",
    "  #GPU timing\n",
    "  cpu_start = time.time()\n",
    "  expected = a + b\n",
    "  cpu_time = (time.time() - cpu_start) * 1000\n",
    "\n",
    "  print(f\"GPU kernel time: {gpu_time:.3f} ms\")\n",
    "  print(f\"CPU NumPy time: {cpu_time:.3f} ms\")\n",
    "  print(f\"Speedup: {cpu_time / gpu_time:.2f}x\")\n",
    "  print(f\"Correct:\" , np.allclose(result , expected))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadb4a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 2: VECTOR ADDITION WITH LESS ELEMENTS\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "@numba.cuda.jit\n",
    "def dummy_compute_kernel(a, b, c):\n",
    "  \"\"\"\n",
    "  Cálculo sencillo para medir el tiempo: c[i] = sqrt(a[i]^2 + b[i]^2)\n",
    "  \"\"\"\n",
    "  idx = cuda.grid(1)\n",
    "  if idx < c.size:\n",
    "    c[idx] = math.sqrt(a[idx] ** 2 + b[idx] ** 2)\n",
    "\n",
    "def main():\n",
    "  N = 1_000_000 #1M elements\n",
    "  a = np.random.randn(N).astype(np.float32)\n",
    "  b = np.random.randn(N).astype(np.float32)\n",
    "  c = np.zeros(N, dtype=np.float32)\n",
    "\n",
    "  # Device arrays\n",
    "  d_a = cuda.to_device(a)\n",
    "  d_b = cuda.to_device(b)\n",
    "  d_c = cuda.to_device(c)\n",
    "\n",
    "  treads_per_block = 256\n",
    "  blocks_per_grid = math.ceil( N / treads_per_block)\n",
    "\n",
    "  # Warrup \"Significa calentar el Chip de la GPU\"\n",
    "  dummy_compute_kernel[blocks_per_grid, treads_per_block](d_a, d_b, d_c)\n",
    "  cuda.synchronize()\n",
    "\n",
    "  # Timed run\n",
    "  start = time.time()\n",
    "  dummy_compute_kernel[blocks_per_grid, treads_per_block](d_a, d_b, d_c)\n",
    "  cuda.synchronize() # IMPORTANT: wait for kernel to finish\n",
    "  end = time.time()\n",
    "\n",
    "  gpu_time = (end - start) * 1000 # Convert to ms\n",
    "\n",
    "  result = d_c.copy_to_host()\n",
    "\n",
    "  # Warrup \"Significa calentar el Chip de la GPU\"\n",
    "  dummy_compute_kernel[blocks_per_grid, treads_per_block](d_a, d_b, d_c)\n",
    "  cuda.synchronize()\n",
    "\n",
    "  # Timed run\n",
    "  start = time.time()\n",
    "  dummy_compute_kernel[blocks_per_grid, treads_per_block](d_a, d_b, d_c)\n",
    "  cuda.synchronize() # IMPORTANT: wait for kernel to finish\n",
    "  end = time.time()\n",
    "\n",
    "  gpu_time = (end - start) * 1000 # Lo convierte a ms\n",
    "\n",
    "  result = d_c.copy_to_host()\n",
    "\n",
    "  #CPU reference\n",
    "  cpu_start = time.time()\n",
    "  expected = np.sqrt(a ** 2 + b ** 2)\n",
    "  cpu_end = time.time()\n",
    "  cpu_time = (cpu_end - cpu_start) * 1000\n",
    "\n",
    "  print(f\"GPU kernel time: {gpu_time:.3f} ms\")\n",
    "  print(f\"CPU NumPy time: {cpu_time:.3f} ms\")\n",
    "  print(f\"Speedup: {cpu_time / gpu_time:.2f}x\")\n",
    "  print(f\"Correct:\" , np.allclose(result , expected))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 3: OPERATIONS WITH SCALARS\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Nvidia profiler\n",
    "@numba.cuda.jit\n",
    "def matrix_scale_kernel(mat, scalar, out):\n",
    "  \"\"\"\n",
    "  Scale every element: out[row,col] = mat[row,col] * scalar\n",
    "  \"\"\"\n",
    "  row, col = cuda.grid(2)\n",
    "  if row < out.shape[0] and col < out.shape[1]:\n",
    "    out[row, col] = mat[row, col] * scalar\n",
    "\n",
    "def main():\n",
    "  rows_large, cols_large = 4096, 4096\n",
    "  mat = np.random.randn(rows_large, cols_large).astype(np.float32)\n",
    "  out = np.zeros_like(mat)\n",
    "  scalar = 2.5\n",
    "  d_mat = cuda.to_device(mat)\n",
    "  d_out = cuda.to_device(out)\n",
    "  threads_per_block = (32, 32)\n",
    "  blocks_per_grid_x = math.ceil(rows_large / threads_per_block[0])\n",
    "  blocks_per_grid_y = math.ceil(cols_large / threads_per_block[1])\n",
    "  blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "  # Warmup (El primer lanzamiento puede ser más lento debido a la compilación JIT)\n",
    "  matrix_scale_kernel[blocks_per_grid, threads_per_block](d_mat, scalar, d_out)\n",
    "  cuda.synchronize()\n",
    "\n",
    "  # GPU timing\n",
    "  start = time.time()\n",
    "  matrix_scale_kernel[blocks_per_grid, threads_per_block](d_mat, scalar, d_out)\n",
    "  cuda.synchronize() # Important: wait for kernel to finish\n",
    "  end = time.time()\n",
    "  gpu_time = (end - start) * 1000 # convert to ms\n",
    "  result = d_out.copy_to_host()\n",
    "\n",
    "  # CPU timing\n",
    "  cpu_start = time.time()\n",
    "  expected = mat * scalar\n",
    "  cpu_end = time.time()\n",
    "  cpu_time = (cpu_end - cpu_start) * 1000\n",
    "\n",
    "  print(f\"GPU kernel time: {gpu_time:.3f} ms\")\n",
    "  print(f\"CPU NumPy time: {cpu_time:.3f} ms\")\n",
    "  print(f\"SpeedUp: {cpu_time / gpu_time:.2f}x\")\n",
    "  print(f\"Correct: \", np.allclose(result, expected))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed04f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 4: MATRIX MULTIPLICATION\n",
    "import numpy as np\n",
    "import numba.cuda as cuda\n",
    "import math\n",
    "import time\n",
    "\n",
    "@numba.cuda.jit\n",
    "def matrix_multiply_kernel(A, B, C):\n",
    "\n",
    "  \"\"\"\n",
    "Multiplicación de matrices simple: C = A @ B\n",
    "Cada hilo calcula un elemento de C.\n",
    "Todas las lecturas de A y B se almacenan en la memoria global (lenta). \n",
    "Modificación: memoria compartida.\n",
    "\n",
    "  A: (M, K)\n",
    "  B: (k, N)\n",
    "  C: (M, N)\n",
    "  \"\"\"\n",
    "\n",
    "  row, col = cuda.grid(2)\n",
    "\n",
    "  M, K = A.shape\n",
    "  K, N = B.shape\n",
    "\n",
    "  if row < M and col < N:\n",
    "    total = 0.0\n",
    "    for k in range(K):\n",
    "      total += A[row, k] * B[k, col]\n",
    "      C[row, col] = total\n",
    "\n",
    "def main():\n",
    "  M, K, N = 1000, 1000, 1000\n",
    "  A = np.random.randn(M, K).astype(np.float32)\n",
    "  B = np.random.randn(K, N).astype(np.float32)\n",
    "  C = np.zeros((M, N), dtype=np.float32)\n",
    "\n",
    "  treads_per_block = (32, 32)\n",
    "  d_A = cuda.to_device(A)\n",
    "  d_B = cuda.to_device(B)\n",
    "  d_C = cuda.to_device(C)\n",
    "\n",
    "  blocks_per_grid_x = (M + treads_per_block[0] - 1) // treads_per_block[0]\n",
    "  blocks_per_grid_y = (N + treads_per_block[1] - 1) // treads_per_block[1]\n",
    "  blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "  # Warrup\n",
    "  matrix_multiply_kernel[blocks_per_grid, treads_per_block](d_A, d_B, d_C)\n",
    "  cuda.synchronize()\n",
    "\n",
    "  # GPU timing\n",
    "  start = time.time()\n",
    "  matrix_multiply_kernel[blocks_per_grid, treads_per_block](d_A, d_B, d_C)\n",
    "  cuda.synchronize()\n",
    "  gpu_time = (time.time() - start) * 1000\n",
    "\n",
    "  C_gpu = d_C.copy_to_host()\n",
    "\n",
    "    # Warrup\n",
    "  matrix_multiply_kernel[blocks_per_grid, treads_per_block](d_A, d_B, d_C)\n",
    "  cuda.synchronize()\n",
    "\n",
    "  # GPU timing\n",
    "  start = time.time()\n",
    "  matrix_multiply_kernel[blocks_per_grid, treads_per_block](d_A, d_B, d_C)\n",
    "  cuda.synchronize()\n",
    "  gpu_time = (time.time() - start) * 1000\n",
    "\n",
    "  C_gpu = d_C.copy_to_host()\n",
    "\n",
    "  # CPU timing\n",
    "  cpu_start = time.time()\n",
    "  C_cpu = A @ B\n",
    "  cpu_time = (time.time() - cpu_start) * 1000\n",
    "\n",
    "  print(f\"GPU kernel time: {gpu_time:.4f} ms\")\n",
    "  print(f\"CPU NumPy time: {cpu_time:.4f} ms\")\n",
    "  print(f\"Speedup: {cpu_time / gpu_time:.2f}x\")\n",
    "  print(f\"Correct: , {np.allclose(C_gpu, C_cpu, atol = 1e-3)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bcddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 5: IMAGE PROCESSOR\n",
    "\n",
    "import numpy as np\n",
    "import numba.cuda as cuda\n",
    "import time\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "# Import \"cv2\" could not be resolved\n",
    "import cv2\n",
    "\n",
    "@numba.cuda.jit\n",
    "def sobel_kernel(img, out):\n",
    "  # Aplicar detección de bordes Sobel: cada hilo procesa un píxel\n",
    "  row, col = cuda.grid(2)\n",
    "  H, W = img.shape\n",
    "\n",
    "  if 0 < row < H - 1 and 0 < col < W - 1:\n",
    "    # Horizontal gradient (Gx)\n",
    "    gx = (-img[row-1,col-1] + img[row-1,col+1] +\n",
    "          -2*img[row,col-1] + 2*img[row,col+1] +\n",
    "          -img[row+1,col-1] + img[row+1,col+1])\n",
    "\n",
    "    # Vertical gradient (Gy)\n",
    "    gy = (-img[row-1,col-1] - 2*img[row-1,col] - img[row-1,col+1] +\n",
    "          img[row+1,col-1] + 2*img[row+1,col] + img[row+1,col+1])\n",
    "\n",
    "    # Magnitud de la ventana\n",
    "    out[row, col] = (gx*gx + gy*gy)**0.5\n",
    "\n",
    "def sobel_opencv(img):\n",
    "  # Abrir CV CPU version usando Sobel\n",
    "  gx = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=3)\n",
    "  gy = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=3)\n",
    "  return np.sqrt(gx**2 + gy**2)\n",
    "\n",
    "# Cargar una imagen 4k de la web\n",
    "urllib.request.urlretrieve(\"https://picsum.photos/3848/2160\",\"image.jpg\")\n",
    "img = Image.open(\"image.jpg\").convert(\"L\")\n",
    "img = np.asarray(img, dtype=np.float32)\n",
    "\n",
    "H, W = img.shape\n",
    "print(f\"Image: {H}x{W} ({W*H:,} pixels)\")\n",
    "\n",
    "d_img = cuda.to_device(img)\n",
    "d_out = cuda.to_device(np.zeros_like(img))\n",
    "\n",
    "threads = (32, 32)\n",
    "blocks = ((W + 15) // 16, (H + 15) // 16)\n",
    "\n",
    "print(f\"Grid: {blocks} blocks x {threads} threads\")\n",
    "\n",
    "# Warmup\n",
    "sobel_kernel[blocks, threads](d_img, d_out)\n",
    "cuda.synchronize()\n",
    "\n",
    "# Time run\n",
    "start = time.time()\n",
    "sobel_kernel[blocks, threads](d_img, d_out)\n",
    "cuda.synchronize()\n",
    "gpu_time = (time.time() - start) * 1000\n",
    "\n",
    "out_gpu = d_out.copy_to_host()\n",
    "\n",
    "# Time CPU\n",
    "start = time.time()\n",
    "out_cpu = sobel_opencv(img)\n",
    "cpu_time = (time.time() - start) * 1000\n",
    "\n",
    "# Resultados\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"GPU: {gpu_time:.2f} ms\")\n",
    "print(f\"CPU: {cpu_time:.2f} ms\")\n",
    "print(f\"Speedup: {cpu_time / gpu_time:.1f}x\")\n",
    "print(f\"Correct: {np.allclose(out_gpu, out_cpu, atol=1e-3)}\")\n",
    "\n",
    "# Ajustar el tamaño de la imagen\n",
    "H, W = img.shape\n",
    "target_w = 256\n",
    "target_h = int(target_w * H / W)\n",
    "\n",
    "def resize_for_plot(array):\n",
    "    normalized = (array / array.max() * 255).astype(np.uint8)\n",
    "    return np.array(Image.fromarray(normalized).resize((target_w, target_h), Image.LANCZOS))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(resize_for_plot(img), cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(resize_for_plot(out_gpu), cmap='gray')\n",
    "plt.title('GPU Sobel Edges')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(resize_for_plot(out_cpu), cmap='gray')\n",
    "plt.title('OpenCV CPU Sobel Edges')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
